{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1084315",
   "metadata": {},
   "source": [
    "# 1-1,ç»“æ„åŒ–æ•°æ®å»ºæ¨¡æµç¨‹èŒƒä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#macç³»ç»Ÿä¸Špytorchå’Œmatplotlibåœ¨jupyterä¸­åŒæ—¶è·‘éœ€è¦æ›´æ”¹ç¯å¢ƒå˜é‡\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d1bbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install -U torchkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchkeras\n",
    "\n",
    "print(\"torch.__version__ = \", torch.__version__)\n",
    "print(\"torchkeras.__version__ = \", torchkeras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a78c0",
   "metadata": {},
   "source": [
    "### ä¸€ï¼Œå‡†å¤‡æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22985769",
   "metadata": {},
   "source": [
    "titanicæ•°æ®é›†çš„ç›®æ ‡æ˜¯æ ¹æ®ä¹˜å®¢ä¿¡æ¯é¢„æµ‹ä»–ä»¬åœ¨Titanicå·æ’å‡»å†°å±±æ²‰æ²¡åèƒ½å¦ç”Ÿå­˜ã€‚\n",
    "\n",
    "ç»“æ„åŒ–æ•°æ®ä¸€èˆ¬ä¼šä½¿ç”¨Pandasä¸­çš„DataFrameè¿›è¡Œé¢„å¤„ç†ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dftrain_raw = pd.read_csv('./eat_pytorch_datasets/titanic/train.csv')\n",
    "dftest_raw = pd.read_csv('./eat_pytorch_datasets/titanic/test.csv')\n",
    "dftrain_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7edf254",
   "metadata": {},
   "source": [
    "å­—æ®µè¯´æ˜ï¼š\n",
    "\n",
    "* Survived:0ä»£è¡¨æ­»äº¡ï¼Œ1ä»£è¡¨å­˜æ´»ã€yæ ‡ç­¾ã€‘\n",
    "* Pclass:ä¹˜å®¢æ‰€æŒç¥¨ç±»ï¼Œæœ‰ä¸‰ç§å€¼(1,2,3) ã€è½¬æ¢æˆonehotç¼–ç ã€‘\n",
    "* Name:ä¹˜å®¢å§“å ã€èˆå»ã€‘\n",
    "* Sex:ä¹˜å®¢æ€§åˆ« ã€è½¬æ¢æˆboolç‰¹å¾ã€‘\n",
    "* Age:ä¹˜å®¢å¹´é¾„(æœ‰ç¼ºå¤±) ã€æ•°å€¼ç‰¹å¾ï¼Œæ·»åŠ â€œå¹´é¾„æ˜¯å¦ç¼ºå¤±â€ä½œä¸ºè¾…åŠ©ç‰¹å¾ã€‘\n",
    "* SibSp:ä¹˜å®¢å…„å¼Ÿå§å¦¹/é…å¶çš„ä¸ªæ•°(æ•´æ•°å€¼) ã€æ•°å€¼ç‰¹å¾ã€‘\n",
    "* Parch:ä¹˜å®¢çˆ¶æ¯/å­©å­çš„ä¸ªæ•°(æ•´æ•°å€¼)ã€æ•°å€¼ç‰¹å¾ã€‘\n",
    "* Ticket:ç¥¨å·(å­—ç¬¦ä¸²)ã€èˆå»ã€‘\n",
    "* Fare:ä¹˜å®¢æ‰€æŒç¥¨çš„ä»·æ ¼(æµ®ç‚¹æ•°ï¼Œ0-500ä¸ç­‰) ã€æ•°å€¼ç‰¹å¾ã€‘\n",
    "* Cabin:ä¹˜å®¢æ‰€åœ¨èˆ¹èˆ±(æœ‰ç¼ºå¤±) ã€æ·»åŠ â€œæ‰€åœ¨èˆ¹èˆ±æ˜¯å¦ç¼ºå¤±â€ä½œä¸ºè¾…åŠ©ç‰¹å¾ã€‘\n",
    "* Embarked:ä¹˜å®¢ç™»èˆ¹æ¸¯å£:Sã€Cã€Q(æœ‰ç¼ºå¤±)ã€è½¬æ¢æˆonehotç¼–ç ï¼Œå››ç»´åº¦ S,C,Q,nanã€‘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a726f38",
   "metadata": {},
   "source": [
    "åˆ©ç”¨Pandasçš„æ•°æ®å¯è§†åŒ–åŠŸèƒ½æˆ‘ä»¬å¯ä»¥ç®€å•åœ°è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æEDAï¼ˆExploratory Data Analysisï¼‰ã€‚\n",
    "\n",
    "labelåˆ†å¸ƒæƒ…å†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e13165",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "# ä»DataFrameä¸­è·å–'Survived'åˆ—çš„å€¼è®¡æ•°ï¼Œå¹¶ç»˜åˆ¶æŸ±çŠ¶å›¾\n",
    "# kind='bar'è¡¨ç¤ºç»˜åˆ¶æŸ±çŠ¶å›¾ï¼Œfigsize=(12, 8)è®¾ç½®å›¾å½¢å¤§å°ï¼Œfontsize=15è®¾ç½®å­—ä½“å¤§å°ï¼Œrot=0è¡¨ç¤ºä¸æ—‹è½¬Xè½´æ ‡ç­¾\n",
    "ax = dftrain_raw['Survived'].value_counts().plot(kind='bar',\n",
    "                                                 figsize=(12, 8), fontsize=15, rot=0)\n",
    "ax.set_ylabel('Counts', fontsize=15)\n",
    "ax.set_xlabel('Survived', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6fa85c",
   "metadata": {},
   "source": [
    "å¹´é¾„åˆ†å¸ƒæƒ…å†µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# ä»æ•°æ®æ¡†ï¼ˆDataFrameï¼‰ä¸­é€‰æ‹© 'Age' åˆ—ï¼Œå¹¶ç»˜åˆ¶ç›´æ–¹å›¾\n",
    "ax = dftrain_raw['Age'].plot(kind='hist',  # ä½¿ç”¨ç›´æ–¹å›¾ç»˜åˆ¶\n",
    "                             bins=20,  # å°†æ•°æ®åˆ†æˆ20ä¸ªåŒºé—´\n",
    "                             color='green',  # è®¾ç½®ç›´æ–¹å›¾çš„é¢œè‰²ä¸ºç´«è‰²\n",
    "                             figsize=(12, 8),  # è®¾ç½®å›¾çš„å°ºå¯¸ä¸º12x8è‹±å¯¸\n",
    "                             fontsize=10)  # è®¾ç½®å­—ä½“å¤§å°ä¸º15\n",
    "\n",
    "# è®¾ç½®yè½´æ ‡ç­¾\n",
    "ax.set_ylabel('Frequency', fontsize=15)  # è®¾ç½®yè½´æ ‡ç­¾ä¸º'Frequency'ï¼Œå­—ä½“å¤§å°ä¸º15\n",
    "\n",
    "# è®¾ç½®xè½´æ ‡ç­¾\n",
    "ax.set_xlabel('Age', fontsize=15)  # è®¾ç½®xè½´æ ‡ç­¾ä¸º'Age'ï¼Œå­—ä½“å¤§å°ä¸º15\n",
    "\n",
    "# æ˜¾ç¤ºç»˜åˆ¶çš„å›¾å½¢\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab6193",
   "metadata": {},
   "source": [
    "å¹´é¾„å’Œlabelçš„ç›¸å…³æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a0979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# ä»æ•°æ®æ¡†ï¼ˆDataFrameï¼‰ä¸­ç­›é€‰ 'Survived' åˆ—ç­‰äº 0 çš„æ•°æ®ï¼Œå¹¶ç»˜åˆ¶å¹´é¾„ï¼ˆ'Age'ï¼‰çš„å¯†åº¦å›¾\n",
    "ax = dftrain_raw.query('Survived == 0')['Age'].plot(kind='density',  # ä½¿ç”¨å¯†åº¦å›¾ç»˜åˆ¶\n",
    "                                                    figsize=(12, 8),  # è®¾ç½®å›¾çš„å°ºå¯¸ä¸º12x8è‹±å¯¸\n",
    "                                                    fontsize=15)  # è®¾ç½®å­—ä½“å¤§å°ä¸º15\n",
    "\n",
    "# ä»æ•°æ®æ¡†ä¸­ç­›é€‰ 'Survived' åˆ—ç­‰äº 1 çš„æ•°æ®ï¼Œå¹¶ç»˜åˆ¶å¹´é¾„çš„å¯†åº¦å›¾\n",
    "dftrain_raw.query('Survived == 1')['Age'].plot(kind='density',  # ä½¿ç”¨å¯†åº¦å›¾ç»˜åˆ¶\n",
    "                                               figsize=(12, 8),  # è®¾ç½®å›¾çš„å°ºå¯¸ä¸º12x8è‹±å¯¸\n",
    "                                               fontsize=15)  # è®¾ç½®å­—ä½“å¤§å°ä¸º15\n",
    "\n",
    "# æ·»åŠ å›¾ä¾‹ï¼Œç”¨äºåŒºåˆ† Survived==0 å’Œ Survived==1 çš„å¯†åº¦å›¾\n",
    "ax.legend(['Survived==0', 'Survived==1'], fontsize=12)\n",
    "\n",
    "# è®¾ç½®yè½´æ ‡ç­¾\n",
    "ax.set_ylabel('Density', fontsize=15)  # è®¾ç½®yè½´æ ‡ç­¾ä¸º'Density'ï¼Œå­—ä½“å¤§å°ä¸º15\n",
    "\n",
    "# è®¾ç½®xè½´æ ‡ç­¾\n",
    "ax.set_xlabel('Age', fontsize=15)  # è®¾ç½®xè½´æ ‡ç­¾ä¸º'Age'ï¼Œå­—ä½“å¤§å°ä¸º15\n",
    "\n",
    "# æ˜¾ç¤ºç»˜åˆ¶çš„å›¾å½¢\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba0563",
   "metadata": {},
   "source": [
    "**ä¸‹é¢ä¸ºæ­£å¼çš„æ•°æ®é¢„å¤„ç†**\n",
    "\n",
    "1. `dfPclass = pd.get_dummies(dfdata['Pclass'])`ï¼š\n",
    "   - `pd.get_dummies` æ˜¯ Pandas åº“ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè¿›è¡Œç‹¬çƒ­ç¼–ç ã€‚å®ƒå°†å…·æœ‰å¤šä¸ªä¸åŒå–å€¼çš„åˆ†ç±»å˜é‡ï¼ˆå¦‚ 'Pclass' åˆ—ï¼‰è½¬æ¢ä¸ºå¤šä¸ªäºŒè¿›åˆ¶ï¼ˆ0æˆ–1ï¼‰çš„åˆ—ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚\n",
    "   - `dfdata['Pclass']` è¡¨ç¤ºä»åä¸º `dfdata` çš„æ•°æ®æ¡†ä¸­é€‰æ‹© 'Pclass' åˆ—ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™ `pd.get_dummies` å‡½æ•°ã€‚\n",
    "   - ç»“æœæ˜¯ä¸€ä¸ªåŒ…å«ç‹¬çƒ­ç¼–ç åæ•°æ®çš„æ–°æ•°æ®æ¡† `dfPclass`ã€‚\n",
    "\n",
    "2. `dfPclass.columns = ['Pclass_' + str(x) for x in dfPclass.columns]`ï¼š\n",
    "   - è¿™ä¸€è¡Œä»£ç ç”¨äºæ›´æ”¹ `dfPclass` æ•°æ®æ¡†çš„åˆ—åã€‚\n",
    "   - `dfPclass.columns` è¿”å› `dfPclass` æ•°æ®æ¡†çš„åˆ—æ ‡ç­¾ã€‚\n",
    "   - `['Pclass_' + str(x) for x in dfPclass.columns]` æ˜¯ä¸€ä¸ªåˆ—è¡¨æ¨å¯¼å¼ï¼Œç”¨äºå°†æ¯ä¸ªåˆ—æ ‡ç­¾éƒ½ä¿®æ”¹ä¸ºä»¥ 'Pclass_' ä½œä¸ºå‰ç¼€ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ ‡è¯†è¿™äº›åˆ—ã€‚\n",
    "\n",
    "3. `dfresult = pd.concat([dfresult, dfPclass], axis=1)`ï¼š\n",
    "   - è¿™ä¸€è¡Œä»£ç ä½¿ç”¨ `pd.concat` å‡½æ•°å°† `dfPclass` æ•°æ®æ¡†ä¸ä¹‹å‰çš„ç»“æœæ•°æ®æ¡† `dfresult` æ°´å¹³è¿æ¥ï¼ˆæŒ‰åˆ—è¿æ¥ï¼‰ã€‚\n",
    "   - `axis=1` å‚æ•°è¡¨ç¤ºæŒ‰åˆ—è¿æ¥ï¼Œå› æ­¤å°† `dfPclass` çš„åˆ—æ·»åŠ åˆ° `dfresult` ä¸­ã€‚\n",
    "   - è¿™æ ·ï¼Œ`dfresult` æ•°æ®æ¡†å°±åŒ…å«äº† 'Pclass' åˆ—çš„ç‹¬çƒ­ç¼–ç ç»“æœï¼Œå…¶ä¸­æ¯ä¸ªä¸åŒçš„ 'Pclass' å–å€¼éƒ½æˆä¸ºäº†æ–°çš„åˆ—ï¼Œåˆ—åä»¥ 'Pclass_' ä¸ºå‰ç¼€ã€‚\n",
    "\n",
    "\n",
    "1. `dfresult['Age'] = dfdata['Age'].fillna(0)`ï¼š\n",
    "   - `dfdata['Age']` è¡¨ç¤ºä»æ•°æ®æ¡† `dfdata` ä¸­é€‰æ‹© 'Age' åˆ—çš„æ•°æ®ã€‚\n",
    "   - `dfdata['Age'].fillna(0)` ç”¨äºå°† 'Age' åˆ—ä¸­çš„ç¼ºå¤±å€¼ï¼ˆNaNï¼ŒNot a Numberï¼‰æ›¿æ¢ä¸º 0ã€‚è¿™æ„å‘³ç€å¦‚æœæŸä¸€è¡Œçš„ 'Age' åˆ—æ•°æ®ç¼ºå¤±ï¼ˆä¸º NaNï¼‰ï¼Œåˆ™åœ¨ `dfresult` æ•°æ®æ¡†ä¸­ç›¸åº”çš„ä½ç½®ä¼šå¡«å……ä¸º 0ã€‚è¿™æ˜¯ä¸€ç§å¤„ç†ç¼ºå¤±å€¼çš„æ–¹æ³•ï¼Œå°†ç¼ºå¤±å€¼æ›¿æ¢ä¸ºä¸€ä¸ªç‰¹å®šçš„æ•°å€¼ã€‚\n",
    "\n",
    "2. `dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')`ï¼š\n",
    "   - `pd.isna(dfdata['Age'])` ç”¨äºæ£€æŸ¥ 'Age' åˆ—ä¸­å“ªäº›å€¼æ˜¯ç¼ºå¤±å€¼ã€‚è¿”å›çš„ç»“æœæ˜¯ä¸€ä¸ªå¸ƒå°”å‹çš„ Seriesï¼Œå…¶ä¸­ç¼ºå¤±å€¼å¯¹åº”çš„ä½ç½®ä¸º Trueï¼Œéç¼ºå¤±å€¼å¯¹åº”çš„ä½ç½®ä¸º Falseã€‚\n",
    "   - `.astype('int32')` ç”¨äºå°†å¸ƒå°”å‹çš„ Series è½¬æ¢ä¸ºæ•´æ•°å‹çš„ Seriesï¼Œå°† True è½¬æ¢ä¸º 1ï¼Œå°† False è½¬æ¢ä¸º 0ã€‚\n",
    "   - æœ€ç»ˆå°†è½¬æ¢åçš„æ•´æ•°å‹ Series å­˜å‚¨åœ¨ `dfresult` æ•°æ®æ¡†ä¸­çš„ 'Age_null' åˆ—ä¸­ã€‚è¿™ä¸€åˆ—çš„å€¼è¡¨ç¤ºå¯¹åº”è¡Œçš„ 'Age' æ˜¯å¦ä¸ºç¼ºå¤±å€¼ï¼Œæ˜¯ç¼ºå¤±å€¼åˆ™ä¸º 1ï¼Œå¦åˆ™ä¸º 0ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28dcead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æ•°æ®é¢„å¤„ç†å‡½æ•°\n",
    "def preprocessing(dfdata):\n",
    "    dfresult = pd.DataFrame()  # åˆ›å»ºä¸€ä¸ªç©ºçš„æ•°æ®æ¡†æ¥å­˜å‚¨å¤„ç†åçš„æ•°æ®\n",
    "\n",
    "    # å¤„ç† 'Pclass' åˆ—ï¼Œå°†å…¶è½¬æ¢æˆç‹¬çƒ­ç¼–ç \n",
    "    dfPclass = pd.get_dummies(dfdata['Pclass'])\n",
    "    dfPclass.columns = ['Pclass_' + str(x) for x in dfPclass.columns]  # ä¸ºæ¯ä¸ªç¼–ç åˆ—æ·»åŠ å‰ç¼€ 'Pclass_'\n",
    "    dfresult = pd.concat([dfresult, dfPclass], axis=1)  # å°†ç¼–ç åçš„åˆ—ä¸ç»“æœæ•°æ®æ¡†åˆå¹¶\n",
    "\n",
    "    # å¤„ç† 'Sex' åˆ—ï¼Œå°†å…¶è½¬æ¢æˆç‹¬çƒ­ç¼–ç \n",
    "    dfSex = pd.get_dummies(dfdata['Sex'])\n",
    "    dfresult = pd.concat([dfresult, dfSex], axis=1)  # å°†ç¼–ç åçš„åˆ—ä¸ç»“æœæ•°æ®æ¡†åˆå¹¶\n",
    "\n",
    "    # å¤„ç† 'Age' åˆ—ï¼Œå°†ç¼ºå¤±å€¼ç”¨ 0 å¡«å……ï¼Œå¹¶æ·»åŠ ä¸€ä¸ªæ–°åˆ— 'Age_null' ä»¥è¡¨ç¤ºæ˜¯å¦æœ‰ç¼ºå¤±å€¼\n",
    "    dfresult['Age'] = dfdata['Age'].fillna(0)\n",
    "    dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')  # å°†ç¼ºå¤±å€¼è½¬æ¢ä¸º 0 å’Œ 1\n",
    "\n",
    "    # å¤„ç† 'SibSp', 'Parch', 'Fare' åˆ—ï¼Œç›´æ¥å°†å®ƒä»¬åŠ å…¥ç»“æœæ•°æ®æ¡†\n",
    "    dfresult['SibSp'] = dfdata['SibSp']\n",
    "    dfresult['Parch'] = dfdata['Parch']\n",
    "    dfresult['Fare'] = dfdata['Fare']\n",
    "\n",
    "    # å¤„ç† 'Cabin' åˆ—ï¼Œæ·»åŠ ä¸€ä¸ªæ–°åˆ— 'Cabin_null' è¡¨ç¤ºæ˜¯å¦æœ‰ç¼ºå¤±å€¼\n",
    "    dfresult['Cabin_null'] = pd.isna(dfdata['Cabin']).astype('int32')\n",
    "\n",
    "    # å¤„ç† 'Embarked' åˆ—ï¼Œå°†å…¶è½¬æ¢æˆç‹¬çƒ­ç¼–ç \n",
    "    dfEmbarked = pd.get_dummies(dfdata['Embarked'], dummy_na=True)  # ä½¿ç”¨dummy_na=Trueæ¥å¤„ç†ç¼ºå¤±å€¼\n",
    "    dfEmbarked.columns = ['Embarked_' + str(x) for x in dfEmbarked.columns]  # ä¸ºæ¯ä¸ªç¼–ç åˆ—æ·»åŠ å‰ç¼€ 'Embarked_'\n",
    "    dfresult = pd.concat([dfresult, dfEmbarked], axis=1)  # å°†ç¼–ç åçš„åˆ—ä¸ç»“æœæ•°æ®æ¡†åˆå¹¶\n",
    "\n",
    "    return dfresult  # è¿”å›å¤„ç†åçš„æ•°æ®æ¡†\n",
    "\n",
    "\n",
    "# è°ƒç”¨æ•°æ®é¢„å¤„ç†å‡½æ•°ï¼Œå°†è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œé¢„å¤„ç†\n",
    "x_train = preprocessing(dftrain_raw).values  # å°†å¤„ç†åçš„æ•°æ®è½¬æ¢ä¸ºNumPyæ•°ç»„\n",
    "y_train = dftrain_raw[['Survived']].values  # è·å–è®­ç»ƒé›†çš„æ ‡ç­¾\n",
    "\n",
    "x_test = preprocessing(dftest_raw).values  # å°†å¤„ç†åçš„æ•°æ®è½¬æ¢ä¸ºNumPyæ•°ç»„\n",
    "y_test = dftest_raw[['Survived']].values  # è·å–æµ‹è¯•é›†çš„æ ‡ç­¾\n",
    "\n",
    "# è¾“å‡ºæ•°æ®é›†çš„å½¢çŠ¶ä¿¡æ¯\n",
    "print(\"x_train.shape =\", x_train.shape)  # è¾“å‡ºè®­ç»ƒé›†ç‰¹å¾çŸ©é˜µçš„å½¢çŠ¶\n",
    "print(\"x_test.shape =\", x_test.shape)  # è¾“å‡ºæµ‹è¯•é›†ç‰¹å¾çŸ©é˜µçš„å½¢çŠ¶\n",
    "print(\"y_train.shape =\", y_train.shape)  # è¾“å‡ºè®­ç»ƒé›†æ ‡ç­¾çš„å½¢çŠ¶\n",
    "print(\"y_test.shape =\", y_test.shape)  # è¾“å‡ºæµ‹è¯•é›†æ ‡ç­¾çš„å½¢çŠ¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6c6d9",
   "metadata": {},
   "source": [
    "è¿›ä¸€æ­¥ä½¿ç”¨DataLoaderå’ŒTensorDatasetå°è£…æˆå¯ä»¥è¿­ä»£çš„æ•°æ®ç®¡é“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d744935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ dl_train\n",
    "dl_train = DataLoader(\n",
    "    TensorDataset(torch.tensor(x_train).float(), torch.tensor(y_train).float()),  # ä½¿ç”¨TensorDatasetåŒ…è£…è®­ç»ƒæ•°æ®\n",
    "    shuffle=True,  # éšæœºæ´—ç‰Œè®­ç»ƒæ•°æ®ï¼Œä»¥å¢åŠ è®­ç»ƒçš„éšæœºæ€§\n",
    "    batch_size=8  # è®¾ç½®æ¯ä¸ªå°æ‰¹é‡çš„å¤§å°ä¸º8\n",
    ")\n",
    "\n",
    "# åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨ dl_val\n",
    "dl_val = DataLoader(\n",
    "    TensorDataset(torch.tensor(x_test).float(), torch.tensor(y_test).float()),  # ä½¿ç”¨TensorDatasetåŒ…è£…éªŒè¯æ•°æ®\n",
    "    shuffle=False,  # ä¸æ´—ç‰ŒéªŒè¯æ•°æ®ï¼Œä»¥ç¡®ä¿éªŒè¯ç»“æœçš„å¯é‡å¤æ€§\n",
    "    batch_size=8  # è®¾ç½®æ¯ä¸ªå°æ‰¹é‡çš„å¤§å°ä¸º8ï¼Œä¸è®­ç»ƒæ—¶ä¸€è‡´\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿­ä»£è®­ç»ƒæ•°æ®åŠ è½½å™¨ dl_train ä¸­çš„æ•°æ®æ‰¹æ¬¡\n",
    "for features, labels in dl_train:\n",
    "    print(\"Features:\", features)  # æ‰“å°å½“å‰æ•°æ®æ‰¹æ¬¡çš„ç‰¹å¾\n",
    "    print(\"Labels:\", labels)  # æ‰“å°å½“å‰æ•°æ®æ‰¹æ¬¡çš„æ ‡ç­¾\n",
    "    break  # ä½¿ç”¨ break è¯­å¥æ¥é€€å‡ºå¾ªç¯ï¼Œåªæ‰“å°ç¬¬ä¸€ä¸ªæ•°æ®æ‰¹æ¬¡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25126768",
   "metadata": {},
   "source": [
    "### äºŒï¼Œå®šä¹‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a275e98",
   "metadata": {},
   "source": [
    "ä½¿ç”¨Pytorché€šå¸¸æœ‰ä¸‰ç§æ–¹å¼æ„å»ºæ¨¡å‹ï¼šä½¿ç”¨nn.SequentialæŒ‰å±‚é¡ºåºæ„å»ºæ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºè‡ªå®šä¹‰æ¨¡å‹ï¼Œç»§æ‰¿nn.ModuleåŸºç±»æ„å»ºæ¨¡å‹å¹¶è¾…åŠ©åº”ç”¨æ¨¡å‹å®¹å™¨è¿›è¡Œå°è£…ã€‚\n",
    "\n",
    "æ­¤å¤„é€‰æ‹©ä½¿ç”¨æœ€ç®€å•çš„nn.Sequentialï¼ŒæŒ‰å±‚é¡ºåºæ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617186ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰åˆ›å»ºç¥ç»ç½‘ç»œçš„å‡½æ•°\n",
    "def create_net():\n",
    "    net = nn.Sequential()  # åˆ›å»ºä¸€ä¸ªSequentialå®¹å™¨ï¼Œç”¨äºæŒ‰é¡ºåºå †å ç¥ç»ç½‘ç»œçš„å±‚æ¬¡\n",
    "\n",
    "    # æ·»åŠ ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œè¾“å…¥ç‰¹å¾æ•°ä¸º15ï¼Œè¾“å‡ºç‰¹å¾æ•°ä¸º20\n",
    "    net.add_module(\"linear1\", nn.Linear(15, 20))\n",
    "    net.add_module(\"relu1\", nn.ReLU())  # æ·»åŠ ReLUæ¿€æ´»å‡½æ•°\n",
    "\n",
    "    # æ·»åŠ ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼Œè¾“å…¥ç‰¹å¾æ•°ä¸º20ï¼Œè¾“å‡ºç‰¹å¾æ•°ä¸º15\n",
    "    net.add_module(\"linear2\", nn.Linear(20, 15))\n",
    "    net.add_module(\"relu2\", nn.ReLU())  # æ·»åŠ ReLUæ¿€æ´»å‡½æ•°\n",
    "\n",
    "    # æ·»åŠ ç¬¬ä¸‰ä¸ªå…¨è¿æ¥å±‚ï¼Œè¾“å…¥ç‰¹å¾æ•°ä¸º15ï¼Œè¾“å‡ºç‰¹å¾æ•°ä¸º1ï¼Œç”¨äºäºŒå…ƒåˆ†ç±»\n",
    "    net.add_module(\"linear3\", nn.Linear(15, 1))\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "# è°ƒç”¨åˆ›å»ºç¥ç»ç½‘ç»œçš„å‡½æ•°ï¼Œåˆ›å»ºä¸€ä¸ªåä¸ºnetçš„ç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "net = create_net()\n",
    "\n",
    "# æ‰“å°ç¥ç»ç½‘ç»œçš„ç»“æ„\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6761227a",
   "metadata": {},
   "source": [
    "### ä¸‰ï¼Œè®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89d5af",
   "metadata": {},
   "source": [
    "Pytorché€šå¸¸éœ€è¦ç”¨æˆ·ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œè®­ç»ƒå¾ªç¯çš„ä»£ç é£æ ¼å› äººè€Œå¼‚ã€‚\n",
    "\n",
    "æœ‰3ç±»å…¸å‹çš„è®­ç»ƒå¾ªç¯ä»£ç é£æ ¼ï¼šè„šæœ¬å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œå‡½æ•°å½¢å¼è®­ç»ƒå¾ªç¯ï¼Œç±»å½¢å¼è®­ç»ƒå¾ªç¯ã€‚\n",
    "\n",
    "æ­¤å¤„ä»‹ç»ä¸€ç§è¾ƒé€šç”¨çš„ä»¿ç…§Kerasé£æ ¼çš„è„šæœ¬å½¢å¼çš„è®­ç»ƒå¾ªç¯ã€‚\n",
    "\n",
    "è¯¥è„šæœ¬å½¢å¼çš„è®­ç»ƒä»£ç ä¸ torchkeras åº“çš„æ ¸å¿ƒä»£ç åŸºæœ¬ä¸€è‡´ã€‚\n",
    "\n",
    "torchkerasè¯¦æƒ…:  https://github.com/lyhue1991/torchkeras \n",
    "\n",
    "ä»¥ä¸‹æ˜¯ä»£ç ä¸­è®¡ç®—æŒ‡æ ‡éƒ¨åˆ†çš„è¯¦ç»†è¯´æ˜ï¼š\n",
    "\n",
    "åœ¨è¿™éƒ¨åˆ†ä»£ç ä¸­ï¼Œé¦–å…ˆå°†ç¥ç»ç½‘ç»œæ¨¡å‹åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼ï¼Œç„¶åè¿­ä»£è®­ç»ƒæ•°æ®åŠ è½½å™¨ (`dl_train`) ä¸­çš„æ•°æ®æ‰¹æ¬¡ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†è¯´æ˜ï¼š\n",
    "\n",
    "- `net.train()`: è®¾ç½®ç¥ç»ç½‘ç»œæ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œè¿™ä¸€æ­¥æ˜¯ä¸ºäº†æ¿€æ´»è®­ç»ƒä¸­ä½¿ç”¨çš„ä¸€äº›ç‰¹å®šåŠŸèƒ½ï¼Œä¾‹å¦‚Dropoutå±‚å’ŒBatch Normalizationå±‚ä¸­çš„è®­ç»ƒæ¨¡å¼ã€‚\n",
    "\n",
    "- `total_loss` å’Œ `step`: ç”¨äºç´¯ç§¯æ¯ä¸ªæ•°æ®æ‰¹æ¬¡çš„æŸå¤±å€¼å’Œè¿­ä»£æ¬¡æ•°ã€‚\n",
    "\n",
    "- `loop`: ä½¿ç”¨ tqdm åº“åˆ›å»ºä¸€ä¸ªè¿­ä»£å™¨ï¼Œç”¨äºæ˜¾ç¤ºè®­ç»ƒè¿›åº¦ï¼Œå¹¶é€šè¿‡ `enumerate` å‡½æ•°éå†è®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸­çš„æ•°æ®æ‰¹æ¬¡ã€‚`total` å‚æ•°ç”¨äºè®¾ç½®è¿­ä»£çš„æ€»æ¬¡æ•°ã€‚\n",
    "\n",
    "- `train_metrics_dict`: ç”¨æ·±æ‹·è´ (`deepcopy`) åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«äº†ç”¨äºå­˜å‚¨æœ¬è½®è®­ç»ƒè¿‡ç¨‹ä¸­è¯„ä¼°æŒ‡æ ‡çš„å¯¹è±¡ã€‚\n",
    "\n",
    "- åœ¨æ¯ä¸ªæ•°æ®æ‰¹æ¬¡çš„è¿­ä»£ä¸­ï¼Œè¿›è¡Œä»¥ä¸‹æ“ä½œï¼š\n",
    "    - `features` å’Œ `labels`: ä»å½“å‰æ•°æ®æ‰¹æ¬¡ä¸­è·å–ç‰¹å¾å’Œæ ‡ç­¾ã€‚\n",
    "\n",
    "    - å‰å‘ä¼ æ’­ (`preds = net(features)`)ï¼šå°†ç‰¹å¾è¾“å…¥ç¥ç»ç½‘ç»œï¼Œè·å¾—é¢„æµ‹å€¼ `preds`ã€‚\n",
    "\n",
    "    - è®¡ç®—æŸå¤±å€¼ (`loss = loss_fn(preds, labels)`)ï¼šä½¿ç”¨é¢„æµ‹å€¼å’ŒçœŸå®æ ‡ç­¾è®¡ç®—æŸå¤±å€¼ï¼Œè¿™é‡Œä½¿ç”¨çš„æŸå¤±å‡½æ•°æ˜¯äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚\n",
    "\n",
    "    - åå‘ä¼ æ’­ (`loss.backward()`)ï¼šæ ¹æ®æŸå¤±å€¼è®¡ç®—æ¢¯åº¦å¹¶åå‘ä¼ æ’­ï¼Œä»¥ä¾¿æ›´æ–°ç¥ç»ç½‘ç»œçš„å‚æ•°ã€‚\n",
    "\n",
    "    - ä¼˜åŒ–å™¨æ­¥éª¤ (`optimizer.step()`)ï¼šæ ¹æ®è®¡ç®—çš„æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°ã€‚\n",
    "\n",
    "    - ä¼˜åŒ–å™¨æ¢¯åº¦æ¸…é›¶ (`optimizer.zero_grad()`)ï¼šæ¸…é›¶ä¼˜åŒ–å™¨ä¸­çš„æ¢¯åº¦ï¼Œå‡†å¤‡å¤„ç†ä¸‹ä¸€ä¸ªæ•°æ®æ‰¹æ¬¡ã€‚\n",
    "\n",
    "    - è®¡ç®—å¹¶è®°å½•è®­ç»ƒæŒ‡æ ‡ (`step_metrics`)ï¼šä½¿ç”¨è¯„ä¼°æŒ‡æ ‡å¯¹è±¡è®¡ç®—å¹¶è®°å½•æ¯ä¸ªæ•°æ®æ‰¹æ¬¡çš„è®­ç»ƒæŒ‡æ ‡ï¼Œä¾‹å¦‚å‡†ç¡®åº¦ã€‚\n",
    "\n",
    "    - è®°å½•å½“å‰æ•°æ®æ‰¹æ¬¡çš„æŸå¤±å€¼å’ŒæŒ‡æ ‡ï¼Œå¹¶æ›´æ–° `total_loss` å’Œ `step`ã€‚\n",
    "\n",
    "    - ä½¿ç”¨ `tqdm` æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯ï¼Œæ˜¾ç¤ºå½“å‰æ•°æ®æ‰¹æ¬¡çš„æŸå¤±å€¼å’ŒæŒ‡æ ‡ã€‚\n",
    "\n",
    "- åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ï¼Œè®¡ç®—å¹¶è®°å½•æ•´ä¸ª epoch çš„å¹³å‡æŸå¤±å€¼å’ŒæŒ‡æ ‡ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ° `history` å­—å…¸ä¸­ã€‚\n",
    "\n",
    "- æœ€åï¼Œé‡ç½®è¯„ä¼°æŒ‡æ ‡å¯¹è±¡çš„çŠ¶æ€ï¼Œä»¥å‡†å¤‡å¤„ç†ä¸‹ä¸€ä¸ª epochã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from torchkeras.metrics import Accuracy  # å¯¼å…¥è‡ªå®šä¹‰æŒ‡æ ‡Accuracy\n",
    "\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªæ‰“å°æ—¥å¿—ä¿¡æ¯çš„å‡½æ•°\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\" + \"==========\" * 8 + \"%s\" % nowtime)\n",
    "    print(str(info) + \"\\n\")\n",
    "\n",
    "\n",
    "# ä½¿ç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°åˆ›å»ºæŸå¤±å‡½æ•°å¯¹è±¡\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# ä½¿ç”¨Adamä¼˜åŒ–å™¨è¿›è¡Œæ¨¡å‹å‚æ•°çš„ä¼˜åŒ–ï¼Œå­¦ä¹ ç‡ä¸º0.01\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå­—å…¸ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™é‡ŒåŒ…æ‹¬å‡†ç¡®åº¦\n",
    "metrics_dict = {\"acc\": Accuracy()}\n",
    "\n",
    "# è®­ç»ƒçš„æ€»è½®æ•°\n",
    "epochs = 20\n",
    "\n",
    "# å®šä¹‰ç”¨äºä¿å­˜æœ€ä½³æ¨¡å‹æƒé‡çš„æ–‡ä»¶è·¯å¾„\n",
    "ckpt_path = 'checkpoint.pt'\n",
    "\n",
    "# Early Stopping ç›¸å…³è®¾ç½®\n",
    "monitor = \"val_acc\"  # ç”¨äºç›‘æ§æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡\n",
    "patience = 5  # å½“è¿ç»­å¤šå°‘è½®æ€§èƒ½æ²¡æœ‰æå‡æ—¶ï¼Œè§¦å‘æ—©åœ\n",
    "mode = \"max\"  # ç›‘æ§æŒ‡æ ‡çš„æ¨¡å¼ï¼Œ\"max\"è¡¨ç¤ºç›‘æ§æŒ‡æ ‡è¶Šå¤§è¶Šå¥½\n",
    "\n",
    "# å­˜å‚¨è®­ç»ƒå†å²ä¿¡æ¯çš„å­—å…¸\n",
    "history = {}\n",
    "\n",
    "# å¼€å§‹è®­ç»ƒå¾ªç¯\n",
    "for epoch in range(1, epochs + 1):\n",
    "    printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "    # 1ï¼Œè®­ç»ƒé˜¶æ®µ -------------------------------------------------\n",
    "    net.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "\n",
    "    total_loss, step = 0, 0\n",
    "\n",
    "    # ä½¿ç”¨tqdmåº“æ˜¾ç¤ºè®­ç»ƒè¿›åº¦ï¼Œå¹¶è®¾ç½®æ–‡ä»¶è¾“å‡ºä¸ºsys.stdout\n",
    "    loop = tqdm(enumerate(dl_train), total=len(dl_train), file=sys.stdout)\n",
    "    train_metrics_dict = deepcopy(metrics_dict)  # å¤åˆ¶è¯„ä¼°æŒ‡æ ‡å­—å…¸ï¼Œç”¨äºå­˜å‚¨æœ¬è½®è®­ç»ƒçš„æŒ‡æ ‡å€¼\n",
    "\n",
    "    for i, batch in loop:\n",
    "\n",
    "        features, labels = batch\n",
    "        # å‰å‘ä¼ æ’­\n",
    "        preds = net(features)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # è®¡ç®—æŒ‡æ ‡\n",
    "        step_metrics = {\"train_\" + name: metric_fn(preds, labels).item()\n",
    "                        for name, metric_fn in train_metrics_dict.items()}\n",
    "\n",
    "        # åˆ›å»ºåŒ…å«æœ¬æ­¥éª¤çš„è®­ç»ƒæŸå¤±å’ŒæŒ‡æ ‡çš„å­—å…¸\n",
    "        step_log = dict({\"train_loss\": loss.item()}, **step_metrics)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        step += 1\n",
    "        if i != len(dl_train) - 1:\n",
    "            loop.set_postfix(**step_log)\n",
    "        else:\n",
    "            # å¦‚æœæ˜¯æœ¬è½®çš„æœ€åä¸€ä¸ªæ‰¹æ¬¡ï¼Œè®¡ç®—æœ¬è½®çš„å¹³å‡è®­ç»ƒæŸå¤±\n",
    "            epoch_loss = total_loss / step\n",
    "\n",
    "            # è®¡ç®—å¹¶è®°å½•æœ¬è½®çš„å¹³å‡è®­ç»ƒæŒ‡æ ‡\n",
    "            epoch_metrics = {\"train_\" + name: metric_fn.compute().item()\n",
    "                             for name, metric_fn in train_metrics_dict.items()}\n",
    "\n",
    "            # åˆ›å»ºåŒ…å«æœ¬è½®çš„å¹³å‡è®­ç»ƒæŸå¤±å’ŒæŒ‡æ ‡çš„å­—å…¸\n",
    "            epoch_log = dict({\"train_loss\": epoch_loss}, **epoch_metrics)\n",
    "\n",
    "            # æ›´æ–°è¿›åº¦æ¡çš„æ˜¾ç¤ºï¼Œæ˜¾ç¤ºæœ¬è½®çš„å¹³å‡è®­ç»ƒæŸå¤±å’ŒæŒ‡æ ‡\n",
    "            loop.set_postfix(**epoch_log)\n",
    "\n",
    "            # é‡ç½®æœ¬è½®çš„è®­ç»ƒæŒ‡æ ‡ï¼Œä»¥ä¾¿ä¸‹ä¸€è½®ä½¿ç”¨\n",
    "            for name, metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset()\n",
    "\n",
    "    # å°†æœ¬è½®çš„è®­ç»ƒæŸå¤±å’ŒæŒ‡æ ‡è®°å½•åˆ°è®­ç»ƒå†å²ä¸­\n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 2ï¼ŒéªŒè¯é˜¶æ®µ -------------------------------------------------\n",
    "    net.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "\n",
    "    total_loss, step = 0, 0\n",
    "    loop = tqdm(enumerate(dl_val), total=len(dl_val), file=sys.stdout)\n",
    "\n",
    "    val_metrics_dict = deepcopy(metrics_dict)  # å¤åˆ¶è¯„ä¼°æŒ‡æ ‡å­—å…¸ï¼Œç”¨äºå­˜å‚¨æœ¬è½®éªŒè¯çš„æŒ‡æ ‡å€¼\n",
    "\n",
    "    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦\n",
    "        for i, batch in loop:\n",
    "\n",
    "            features, labels = batch\n",
    "\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            preds = net(features)\n",
    "            loss = loss_fn(preds, labels)\n",
    "\n",
    "            # è®¡ç®—æŒ‡æ ‡\n",
    "            step_metrics = {\"val_\" + name: metric_fn(preds, labels).item()\n",
    "                            for name, metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "            # åˆ›å»ºåŒ…å«æœ¬æ­¥éª¤çš„éªŒè¯æŸå¤±å’ŒæŒ‡æ ‡çš„å­—å…¸\n",
    "            step_log = dict({\"val_loss\": loss.item()}, **step_metrics)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step += 1\n",
    "            if i != len(dl_val) - 1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                # å¦‚æœæ˜¯æœ¬è½®çš„æœ€åä¸€ä¸ªæ‰¹æ¬¡ï¼Œè®¡ç®—æœ¬è½®çš„å¹³å‡éªŒè¯æŸå¤±\n",
    "                epoch_loss = (total_loss / step)\n",
    "\n",
    "                # è®¡ç®—å¹¶è®°å½•æœ¬è½®çš„å¹³å‡éªŒè¯æŒ‡æ ‡\n",
    "                epoch_metrics = {\"val_\" + name: metric_fn.compute().item()\n",
    "                                 for name, metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "                # åˆ›å»ºåŒ…å«æœ¬è½®çš„å¹³å‡éªŒè¯æŸå¤±å’ŒæŒ‡æ ‡çš„å­—å…¸\n",
    "                epoch_log = dict({\"val_loss\": epoch_loss}, **epoch_metrics)\n",
    "\n",
    "                # æ›´æ–°è¿›åº¦æ¡çš„æ˜¾ç¤ºï¼Œæ˜¾ç¤ºæœ¬è½®çš„å¹³å‡éªŒè¯æŸå¤±å’ŒæŒ‡æ ‡\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                # é‡ç½®æœ¬è½®çš„éªŒè¯æŒ‡æ ‡ï¼Œä»¥ä¾¿ä¸‹ä¸€è½®ä½¿ç”¨\n",
    "                for name, metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "\n",
    "    # å°†æœ¬è½®çš„éªŒè¯æŸå¤±å’ŒæŒ‡æ ‡è®°å½•åˆ°è®­ç»ƒå†å²ä¸­\n",
    "    epoch_log[\"epoch\"] = epoch\n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 3ï¼ŒEarly Stopping -------------------------------------------------\n",
    "    arr_scores = history[monitor]  # è·å–å†å²ä¸Šçš„ç›‘æ§æŒ‡æ ‡æ•°å€¼\n",
    "    best_score_idx = np.argmax(arr_scores) if mode == \"max\" else np.argmin(arr_scores)\n",
    "\n",
    "    # å¦‚æœå½“å‰çš„æ¨¡å‹æ€§èƒ½æ¯”å†å²ä¸Šçš„æœ€ä½³æ€§èƒ½å¥½ï¼Œä¿å­˜å½“å‰æ¨¡å‹æƒé‡\n",
    "    if best_score_idx == len(arr_scores) - 1:\n",
    "        torch.save(net.state_dict(), ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "                                                          arr_scores[best_score_idx]), file=sys.stderr)\n",
    "\n",
    "    # å¦‚æœè¿ç»­å¤šè½®æ€§èƒ½æ²¡æœ‰æå‡ï¼Œè§¦å‘æ—©åœ\n",
    "    if len(arr_scores) - best_score_idx > patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor, patience), file=sys.stderr)\n",
    "        break\n",
    "\n",
    "    # æ¢å¤å†å²ä¸Šçš„æœ€ä½³æ¨¡å‹æƒé‡\n",
    "    net.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "# å°†è®­ç»ƒå†å²ä¿¡æ¯è½¬ä¸ºDataFrameæ ¼å¼\n",
    "dfhistory = pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7f3b3",
   "metadata": {},
   "source": [
    "### å››ï¼Œè¯„ä¼°æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbce96",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬é¦–å…ˆè¯„ä¼°ä¸€ä¸‹æ¨¡å‹åœ¨è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸Šçš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a731173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'  # æŒ‡å®šç»˜å›¾æ ¼å¼ä¸ºSVG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºç»˜åˆ¶è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡æ›²çº¿\n",
    "def plot_metric(dfhistory, metric):\n",
    "    # ä»è®­ç»ƒå†å²æ•°æ®ä¸­è·å–è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡çš„æ•°å€¼\n",
    "    train_metrics = dfhistory[\"train_\" + metric]\n",
    "    val_metrics = dfhistory['val_' + metric]\n",
    "    # åˆ›å»ºä¸€ä¸ªè¡¨ç¤ºè½®æ¬¡çš„èŒƒå›´\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    # ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡æ›²çº¿ï¼Œä½¿ç”¨è“è‰²åœ†ç‚¹å½¢çŠ¶çš„çº¿æ¡\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    # ç»˜åˆ¶éªŒè¯æŒ‡æ ‡æ›²çº¿ï¼Œä½¿ç”¨çº¢è‰²å®çº¿çš„çº¿æ¡\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    # è®¾ç½®å›¾è¡¨æ ‡é¢˜\n",
    "    plt.title('Training and validation ' + metric)\n",
    "    # è®¾ç½®Xè½´æ ‡ç­¾\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    # è®¾ç½®Yè½´æ ‡ç­¾\n",
    "    plt.ylabel(metric)\n",
    "    # æ·»åŠ å›¾ä¾‹ï¼Œè¡¨ç¤ºè®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡å¯¹åº”çš„çº¿æ¡\n",
    "    plt.legend([\"train_\" + metric, 'val_' + metric])\n",
    "    # æ˜¾ç¤ºå›¾è¡¨\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b47c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory, \"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4494b",
   "metadata": {},
   "source": [
    "### äº”ï¼Œä½¿ç”¨æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œæ¨æ–­ï¼Œè®¡ç®—å‰10ä¸ªæ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡\n",
    "# ä½¿ç”¨ torch.sigmoid å‡½æ•°å°†æ¨¡å‹è¾“å‡ºçš„ logits è½¬æ¢ä¸ºæ¦‚ç‡å€¼\n",
    "\n",
    "y_pred_probs = torch.sigmoid(\n",
    "    net(torch.tensor(x_test[0:10]).float())  # å°†å‰10ä¸ªæµ‹è¯•æ ·æœ¬è½¬æ¢ä¸º PyTorch å¼ é‡å¹¶è¿›è¡Œæ¨æ–­\n",
    ").data\n",
    "\n",
    "# è¾“å‡ºé¢„æµ‹æ¦‚ç‡å€¼\n",
    "y_pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31cb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¢„æµ‹ç±»åˆ«\n",
    "# å¦‚æœé¢„æµ‹çš„æ¦‚ç‡å€¼å¤§äº0.5ï¼Œåˆ™å°†ç±»åˆ«è®¾ç½®ä¸º1ï¼Œå¦åˆ™è®¾ç½®ä¸º0\n",
    "\n",
    "# ä½¿ç”¨ torch.where å‡½æ•°è¿›è¡Œç±»åˆ«çš„åˆ¤å®š\n",
    "y_pred = torch.where(\n",
    "    y_pred_probs > 0.5,  # é¢„æµ‹æ¦‚ç‡å€¼å¤§äº0.5æ—¶ï¼Œä¸ºæ­£ç±»åˆ«\n",
    "    torch.ones_like(y_pred_probs),  # æ­£ç±»åˆ«æ ‡ç­¾ï¼ˆ1ï¼‰\n",
    "    torch.zeros_like(y_pred_probs)  # è´Ÿç±»åˆ«æ ‡ç­¾ï¼ˆ0ï¼‰\n",
    ")\n",
    "\n",
    "# è¾“å‡ºé¢„æµ‹çš„ç±»åˆ«\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe8bba",
   "metadata": {},
   "source": [
    "### å…­ï¼Œä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb7506",
   "metadata": {},
   "source": [
    "Pytorch æœ‰ä¸¤ç§ä¿å­˜æ¨¡å‹çš„æ–¹å¼ï¼Œéƒ½æ˜¯é€šè¿‡è°ƒç”¨pickleåºåˆ—åŒ–æ–¹æ³•å®ç°çš„ã€‚\n",
    "\n",
    "ç¬¬ä¸€ç§æ–¹æ³•åªä¿å­˜æ¨¡å‹å‚æ•°ã€‚\n",
    "\n",
    "ç¬¬äºŒç§æ–¹æ³•ä¿å­˜å®Œæ•´æ¨¡å‹ã€‚\n",
    "\n",
    "æ¨èä½¿ç”¨ç¬¬ä¸€ç§ï¼Œç¬¬äºŒç§æ–¹æ³•å¯èƒ½åœ¨åˆ‡æ¢è®¾å¤‡å’Œç›®å½•çš„æ—¶å€™å‡ºç°å„ç§é—®é¢˜ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113eb43",
   "metadata": {},
   "source": [
    "**1ï¼Œä¿å­˜æ¨¡å‹å‚æ•°(æ¨è)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6098000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰“å°ç¥ç»ç½‘ç»œæ¨¡å‹çš„çŠ¶æ€å­—å…¸ä¸­çš„æ‰€æœ‰é”®\n",
    "print(net.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜æ¨¡å‹å‚æ•°åˆ°æ–‡ä»¶ \"./data/net_parameter.pt\"\n",
    "torch.save(net.state_dict(), \"./data/net_parameter.pt\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªæ–°çš„ç¥ç»ç½‘ç»œæ¨¡å‹ net_clone\n",
    "net_clone = create_net()\n",
    "\n",
    "# åŠ è½½ä¿å­˜çš„æ¨¡å‹å‚æ•°åˆ° net_clone\n",
    "net_clone.load_state_dict(torch.load(\"./data/net_parameter.pt\"))\n",
    "\n",
    "# å¯¹å‰10ä¸ªæµ‹è¯•æ ·æœ¬è¿›è¡Œæ¨æ–­ï¼Œä½¿ç”¨æ–°çš„æ¨¡å‹ net_clone\n",
    "# ä½¿ç”¨ torch.sigmoid å‡½æ•°å°†æ¨¡å‹è¾“å‡ºçš„ logits è½¬æ¢ä¸ºæ¦‚ç‡å€¼\n",
    "predictions = torch.sigmoid(net_clone.forward(torch.tensor(x_test[0:10]).float())).data\n",
    "\n",
    "# è¾“å‡ºé¢„æµ‹çš„æ¦‚ç‡å€¼\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee51ce5",
   "metadata": {},
   "source": [
    "**2ï¼Œä¿å­˜å®Œæ•´æ¨¡å‹(ä¸æ¨è)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c969c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜æ•´ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹åˆ°æ–‡ä»¶ \"./data/net_model.pt\"\n",
    "torch.save(net, './data/net_model.pt')\n",
    "\n",
    "# åŠ è½½æ•´ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "net_loaded = torch.load('./data/net_model.pt')\n",
    "\n",
    "# å¯¹å‰10ä¸ªæµ‹è¯•æ ·æœ¬è¿›è¡Œæ¨æ–­ï¼Œä½¿ç”¨åŠ è½½çš„æ¨¡å‹ net_loaded\n",
    "# ä½¿ç”¨ torch.sigmoid å‡½æ•°å°†æ¨¡å‹è¾“å‡ºçš„ logits è½¬æ¢ä¸ºæ¦‚ç‡å€¼\n",
    "predictions = torch.sigmoid(net_loaded(torch.tensor(x_test[0:10]).float())).data\n",
    "\n",
    "# è¾“å‡ºé¢„æµ‹çš„æ¦‚ç‡å€¼\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eacb75",
   "metadata": {},
   "source": [
    "**å¦‚æœæœ¬ä¹¦å¯¹ä½ æœ‰æ‰€å¸®åŠ©ï¼Œæƒ³é¼“åŠ±ä¸€ä¸‹ä½œè€…ï¼Œè®°å¾—ç»™æœ¬é¡¹ç›®åŠ ä¸€é¢—æ˜Ÿæ˜Ÿstarâ­ï¸ï¼Œå¹¶åˆ†äº«ç»™ä½ çš„æœ‹å‹ä»¬å–”ğŸ˜Š!** \n",
    "\n",
    "å¦‚æœå¯¹æœ¬ä¹¦å†…å®¹ç†è§£ä¸Šæœ‰éœ€è¦è¿›ä¸€æ­¥å’Œä½œè€…äº¤æµçš„åœ°æ–¹ï¼Œæ¬¢è¿åœ¨å…¬ä¼—å·\"ç®—æ³•ç¾é£Ÿå±‹\"ä¸‹ç•™è¨€ã€‚ä½œè€…æ—¶é—´å’Œç²¾åŠ›æœ‰é™ï¼Œä¼šé…Œæƒ…äºˆä»¥å›å¤ã€‚\n",
    "\n",
    "ä¹Ÿå¯ä»¥åœ¨å…¬ä¼—å·åå°å›å¤å…³é”®å­—ï¼š**åŠ ç¾¤**ï¼ŒåŠ å…¥è¯»è€…äº¤æµç¾¤å’Œå¤§å®¶è®¨è®ºã€‚\n",
    "\n",
    "![ç®—æ³•ç¾é£Ÿå±‹logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
